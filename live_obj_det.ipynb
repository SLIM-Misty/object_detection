{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add language model stuff 11-8-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "def crop_ADD_image(box, img:PIL.Image):\n",
    "    '''\n",
    "    given a likely object; \n",
    "    crop box --> to conv-net --> lang model\n",
    "    OR, if predicting, crop box --> conv-net --> retrieve prediction + lang model\n",
    "    '''\n",
    "    # 8-10 from s19/Model.py\n",
    "    size = 224\n",
    "    \n",
    "    print(\"image shape\",np.array(img).shape)\n",
    "    \n",
    "    img_resized = img.resize(size=(size, size))    \n",
    "    cleanImg = img_resized.copy();\n",
    "    \n",
    "    print(\"image shape\",np.array(cleanImg).shape)\n",
    "    \n",
    "    bottom = box[0] * 224\n",
    "    left = box[1] * 224\n",
    "    top = box[2] * 224\n",
    "    right  = box[3] * 224\n",
    "    # these box coordinates are not appropriate for the formatting task...\n",
    "    \n",
    "    print(\"\\n*****************\\ncropping?\",np.array(cleanImg.crop((left,top,right,bottom))))\n",
    "    \n",
    "    formattedBox = (left, top, right, bottom) # coordinates need to be corrected for crop\n",
    "    \n",
    "    print('crop here:', formattedBox)\n",
    "    \n",
    "    croppedImg = cleanImg.crop(formattedBox)\n",
    "    \n",
    "    croppedImg = np.array(croppedImg) \n",
    "    print('cropped image shape',croppedImg.shape)\n",
    "    croppedImg = croppedImg[:, :, ::-1].copy()\n",
    "    \n",
    "    languageFeed.append(croppedImg) \n",
    "#     return croppedImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(robot):\n",
    "    global speak\n",
    "    global prediction\n",
    "    preds = []\n",
    "    for i in range(len(languageFeed)):\n",
    "        currentImg = languageFeed.pop()\n",
    "        preds.append(predModel.predictImageWord(currentImg))\n",
    "    preds = [item[0] for item in preds] #remove probability number in tuple\n",
    "    prediction = collections.Counter(preds).most_common(1)[0][0]\n",
    "#     speak = True\n",
    "    robot.say_text(prediction).wait_for_completed()\n",
    "    #return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "dir_path = '/home/david/GIT/cs481-senior-design/s19/'\n",
    "sys.path.append(dir_path)\n",
    "\n",
    "import LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/keras/utils/conv_utils.py:82: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.copy(kernel[slices])\n",
      "/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.20.2 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "dir_path = '/home/david/GIT/cs481-senior-design/s19/'\n",
    "with open(dir_path+'language-model.pickle', 'rb') as handle:\n",
    "    predModel = pickle.load(handle) #trying to load a LanguageModel type    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "dir_path = '/home/david/GIT/language-acquisition/'\n",
    "sys.path.append(dir_path)\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use(\"Qt5Agg\") #Makes imshow work on mac\n",
    "from matplotlib import pyplot as plt\n",
    "from classes.mask_rcnn import MaskRCNN\n",
    "#from Model import Model, draw_boxes\n",
    "\n",
    "import queue\n",
    "import time\n",
    "import threading\n",
    "import numpy as np\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/david/GIT/language-acquisition/classes/mask_rcnn.py:90: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/david/GIT/language-acquisition/classes/mask_rcnn.py:32: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/tensorflow/models/research/object_detection/utils/label_map_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "obj_det_path = \"/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/tensorflow/models/research/object_detection/\"\n",
    "\n",
    "# faster_rcnn_inception_resnet_v2_atrous_oid_v4_2018_12_12'\n",
    "MODEL_NAME = obj_det_path + 'd2s_model'\n",
    "\n",
    "path = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "image_dimensions = (240, 320, 3)\n",
    "model = MaskRCNN(path, image_dimensions)\n",
    "\n",
    "PATH_TO_LABELS = os.path.join(obj_det_path + 'd2s_model', 'label_map.pbtxt')\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/keras/utils/conv_utils.py:82: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.copy(kernel[slices])\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "sys.path.append('/home/david/GIT/cozmo-python-sdk/')\n",
    "sys.path.append('/home/david/GIT/cozmo-python-sdk/src')\n",
    "sys.path.append('/home/david/GIT/cozmo-python-sdk/src/cozmo')\n",
    "\n",
    "from src.cozmo.util import degrees, Angle, distance_mm, speed_mmps\n",
    "from src import cozmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def handle_image(evt, obj=None, tap_count=None,  **kwargs):\n",
    "    try:\n",
    "        if(imageQueue.empty()): # \n",
    "            imageQueue.put_nowait(evt.image)\n",
    "    except queue.Full:\n",
    "        pass\n",
    "\n",
    "def configure_camera(robot, exposure_amount, gain_amount, color):\n",
    "    robot.camera.color_image_enabled = color\n",
    "    # Lerp exposure between min and max times\n",
    "    min_exposure = robot.camera.config.min_exposure_time_ms\n",
    "    max_exposure = robot.camera.config.max_exposure_time_ms\n",
    "    exposure_time = (1-exposure_amount)*min_exposure + exposure_amount*max_exposure\n",
    "    # Lerp gain\n",
    "    min_gain = robot.camera.config.min_gain\n",
    "    max_gain = robot.camera.config.max_gain\n",
    "    actual_gain = (1-gain_amount)*min_gain + gain_amount*max_gain\n",
    "    robot.camera.set_manual_exposure(exposure_time, actual_gain)\n",
    "\n",
    "def detect_object(robot, minimum_threshold=0.10):\n",
    "    '''\n",
    "    run object detection on images from imageQueue\n",
    "    returns: populates objectQueue with Object data. \n",
    "    '''\n",
    "    print('Detect Images started')\n",
    "    counter = 0\n",
    "    while(True):\n",
    "        if(not imageQueue.empty()): \n",
    "            try:\n",
    "                img = imageQueue.get()\n",
    "                image_np = load_image_into_numpy_array(img)\n",
    "                output_dict = model.detect(image_np)\n",
    "\n",
    "                indices = [list(output_dict['detection_scores']).index(o) \n",
    "                           for o in output_dict['detection_scores'] \n",
    "                           if o > minimum_threshold]\n",
    "                if len(indices) > 0 and objQueue.empty():    \n",
    "                    for i in range(len(indices)):\n",
    "                        boxes = [output_dict['detection_boxes'][i] for i in indices]\n",
    "                        b = boxes[i]\n",
    "                        real_obj = obj_check(b)\n",
    "                        if not real_obj[0]: \n",
    "                            continue\n",
    "                        else: \n",
    "                            classes = [output_dict['detection_classes'][i] for i in indices]\n",
    "                            scores = [output_dict['detection_scores'][i] for i in indices]\n",
    "                            bestObj_i = i \n",
    "                            box = boxes[bestObj_i]\n",
    "                            score = scores[bestObj_i]\n",
    "                            label = classes[bestObj_i]\n",
    "\n",
    "                            if objQueue.empty():\n",
    "                                plt.clf() # We need to clear the plot so that we are not plotting every image each iteration. \n",
    "                                # (If we don't we will get increasing delay)\n",
    "                                objQueue.put_nowait(box)\n",
    "                                \n",
    "                                # add image to the language feed\n",
    "                                crop_ADD_image(box, img.copy())\n",
    "                                \n",
    "                                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                                    image_np,\n",
    "                                    output_dict['detection_boxes'],\n",
    "                                    output_dict['detection_classes'],\n",
    "                                    output_dict['detection_scores'],\n",
    "                                    category_index,\n",
    "                                    use_normalized_coordinates=True,\n",
    "                                    min_score_thresh=minimum_threshold,\n",
    "                                    line_thickness=8,\n",
    "                                    max_boxes_to_draw=3)\n",
    "                                plt.imshow(image_np)\n",
    "                                plt.pause(0.001) # imshow needs time to plot the image. Need this to display the image\n",
    "                                \n",
    "            except queue.Empty:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_check(go_box):\n",
    "    '''\n",
    "    tf documentation is wrong --\n",
    "    order is not: [ymin, ymax, xmin, xmax]\n",
    "    order IS: [ymin, xmin, ymax, xmax]\n",
    "    '''\n",
    "    ymin = go_box[0]\n",
    "    xmin = go_box[1]\n",
    "    ymax = go_box[2]\n",
    "    xmax = go_box[3]\n",
    "    height = ymax - ymin\n",
    "    width = xmax - xmin\n",
    "    area = height * width    \n",
    "    x_center = (width/2) + xmin\n",
    "    y_center = (height/2) + ymin\n",
    "    # the condition that determines if a bounding box contains an object\n",
    "    if area > 0.08: \n",
    "#         print('check failed!')\n",
    "        return (False, y_center, x_center)\n",
    "    else: \n",
    "#         print('check passed')\n",
    "        return (True, y_center, x_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_coordinates(go_box):\n",
    "    real_obj = obj_check(go_box)    \n",
    "    x_center = real_obj[2]\n",
    "    y_center = real_obj[1]\n",
    "    print('y:', y_center, 'x:', x_center)\n",
    "    if not real_obj[0]: # break 'go_to' loop\n",
    "        drive_dist = 1000 \n",
    "        turn_angle = 1000\n",
    "    else:\n",
    "        # we want x_center to be 0.5, turn right -> (-) / turn left -> (+)\n",
    "        if x_center > 0.56 or x_center < 0.44:\n",
    "            x_diff = x_center - 0.5\n",
    "            turn_angle = (x_diff * (-50)) / 2 \n",
    "        else: turn_angle = 0 # break 'go_to' loop\n",
    "        # we want y-center to be = 0.42, (-) -> backwards, (+) -> forwards   \n",
    "        if y_center > 0.48 or y_center < 0.36:\n",
    "            y_diff = y_center - 0.42\n",
    "            # need to account for parallax -- things far away approach slowly; things close up approach quickly\n",
    "            base = y_diff * (-10)\n",
    "            drive_dist = np.power(base,4)\n",
    "        else: drive_dist = 0 # break 'go_to' loop\n",
    "    return drive_dist, turn_angle\n",
    "\n",
    "def go_to_obj(robot):    \n",
    "    last_drive = 1000\n",
    "    last_turn = 1000\n",
    "    while True:\n",
    "        if not objQueue.empty():\n",
    "            box = objQueue.get()\n",
    "            print(\"go to \", box)\n",
    "            drive_dist, turn_angle = find_coordinates(box)\n",
    "            print('turned ', turn_angle, 'degrees', '/ drove', drive_dist,'mm')\n",
    "            # these conditions break 'go_to' loop\n",
    "            if drive_dist > last_drive: break\n",
    "            elif turn_angle > last_turn: break\n",
    "            if turn_angle == 0 and drive_dist == 0: break\n",
    "            robot.turn_in_place(degrees(turn_angle),in_parallel=True)\n",
    "            last_turn = turn_angle\n",
    "            robot.drive_straight(distance_mm(drive_dist), speed_mmps(40), should_play_anim=False, in_parallel=True)\n",
    "            last_drive = drive_dist\n",
    "            robot.wait_for_all_actions_completed()  \n",
    "    print('Stop going to object')\n",
    "    return drive_dist, turn_angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def find_object(robot):\n",
    "    print('Find objects started')\n",
    "    \n",
    "    confidence = 0 # added for language prediction\n",
    "    \n",
    "    while True:\n",
    "        if objQueue.empty():\n",
    "#             robot.turn_in_place(degrees(360), speed=Angle(0.3), accel=Angle(0.3))\n",
    "            robot.drive_wheels(l_wheel_speed=-10, r_wheel_speed=10)\n",
    "        else:\n",
    "            robot.stop_all_motors()\n",
    "            robot.wait_for_all_actions_completed()\n",
    "            # the 'go to object reorientation loop'\n",
    "            predicting = False\n",
    "            drive, turn = go_to_obj(robot)\n",
    "            if drive == 0 and turn == 0:    \n",
    "                break\n",
    "            else:\n",
    "                print('find object failed') \n",
    "#                 predict(robot)\n",
    "                pass\n",
    "            print('return to object search')\n",
    "    print('Object found!')\n",
    "    predict(robot)\n",
    "#     predicting = True # predict in this instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cozmo_program(robot: cozmo.robot.Robot):\n",
    "    print('starting pose',robot.pose)\n",
    "    robot.clear_idle_animation()\n",
    "    robot.stop_freeplay_behaviors()\n",
    "    robot.set_idle_animation(cozmo.anim.Triggers.NeutralFace)   \n",
    "    robot.set_lift_height(1.0).wait_for_completed()\n",
    "    robot.set_head_angle(cozmo.robot.MIN_HEAD_ANGLE).wait_for_completed()\n",
    "\n",
    "    exposure_amount = 0.1 # Range: [0,1]\n",
    "    gain_amount = 1.0 # Range: [0,1]\n",
    "    color = True\n",
    "    configure_camera(robot, exposure_amount, gain_amount, color)\n",
    "    \n",
    "    robot.add_event_handler(cozmo.camera.EvtNewRawCameraImage, handle_image)\n",
    "    print(\"Added event handler\")\n",
    "    \n",
    "    minimum_threshold = 0.10\n",
    "    \n",
    "    threading.Thread(target=find_object, args=(robot,)).start()\n",
    "    threading.Thread(target=detect_object, args=(robot,minimum_threshold,)).start() # \n",
    "    \n",
    "    while True:\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-08 13:09:36,334 cozmo.general INFO     App connection established. sdk_version=1.4.11.dev0 cozmoclad_version=3.4.0 app_build_version=00003.00004.00000\n",
      "2019-11-08 13:09:36,335 cozmo.general INFO     Found robot id=1\n",
      "2019-11-08 13:09:36,341 cozmo.general INFO     Connected to Android device serial=ZY223325P4\n",
      "2019-11-08 13:09:36,466 cozmo.general INFO     Robot id=1 serial=024086a7 initialized OK\n",
      "2019-11-08 13:09:36,576 cozmo.general INFO     Sending abort request for all actions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting pose <Pose <Position x: 0.00 y: 0.00 z: 0.00> <Quaternion q0: 1.00 q1: 0.00 q2: 0.00 q3: -0.02 (angle_z: <Angle -0.04 radians (-2.01 degrees)>)> origin_id=7>\n",
      "Added event handler\n",
      "Find objects started\n",
      "Detect Images started\n",
      "image shape (240, 320, 3)\n",
      "image shape (224, 224, 3)\n",
      "\n",
      "*****************\n",
      "cropping? <PIL.Image.Image image mode=RGB size=24x0 at 0x7F8B683E2ED0>\n",
      "crop here: (0.0, 22.59876322746277, 24.122873544692993, 0.0)\n",
      "cropped image shape ()\n",
      "go to  [0.         0.         0.10088734 0.1076914 ]\n",
      "y: 0.05044366791844368 x: 0.05384569987654686\n",
      "turned  11.153857503086329 degrees / drove 186.51879111875104 mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-9-ae6683edccd8>\", line 63, in detect_object\n",
      "    crop_ADD_image(box, img.copy())\n",
      "  File \"<ipython-input-1-4722d80c58f3>\", line 35, in crop_ADD_image\n",
      "    croppedImg = croppedImg[:, :, ::-1].copy()\n",
      "IndexError: too many indices for array\n",
      "\n",
      "2019-11-08 13:10:16,095 cozmo.general INFO     Shutting down connection\n",
      "2019-11-08 13:10:16,122 cozmo.general INFO     Android serial=ZY223325P4 disconnected.\n",
      "2019-11-08 13:10:16,143 cozmo.general INFO     Exit requested by user\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections\n",
    "imageQueue = queue.Queue(maxsize=1)\n",
    "objQueue = queue.Queue(maxsize=1)\n",
    "languageFeed = collections.deque(maxlen=8)\n",
    "\n",
    "cozmo.run_program(cozmo_program, use_viewer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Good neutral animations?**\n",
    "\n",
    "    # DroneModeIdle, 161\n",
    "    # NeutralFace, 326\n",
    "    # OnboardingIdle, 362\n",
    "    # VC_NoFollowupCommand_NoFace, 549"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-16-17b9544c6c30>\", line 26, in <module>\n",
      "    '''\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/IPython/core/displayhook.py\", line 268, in __call__\n",
      "    self.finish_displayhook()\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/ipykernel/displayhook.py\", line 77, in finish_displayhook\n",
      "    sys.stderr.flush()\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/ipykernel/iostream.py\", line 351, in flush\n",
      "    if not evt.wait(self.flush_timeout):\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/threading.py\", line 552, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/threading.py\", line 300, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/david/anaconda3/envs/cozmo/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# RAMBLING AROUND + AVOIDING CLIFF CODE \n",
    "\n",
    "        time.sleep(0.1)\n",
    "        l_turn = random.choice([0,-10,-20,30])\n",
    "        l_speed = 40 + l_turn\n",
    "        r_turn = random.choice([0,-10,20,-30])\n",
    "        r_speed = 40 + r_turn \n",
    "#         print(r_speed, l_speed)        \n",
    "        if robot.is_cliff_detected: # or not robot.is_localized\n",
    "            robot.stop_all_motors()\n",
    "            robot.wait_for_all_actions_completed() \n",
    "            \n",
    "            #sometimes, the robot skips 'drive wheels' and goes straight into a turn\n",
    "            #with disastrous results...\n",
    "            \n",
    "            correct = random.choice([-145,145])\n",
    "            robot.drive_wheels(l_wheel_speed=-60, r_wheel_speed=-60, duration=1.75)\n",
    "            robot.wait_for_all_actions_completed()\n",
    "            print(correct)\n",
    "            if robot.has_in_progress_actions:\n",
    "                robot.drive_wheels(l_wheel_speed=-60, r_wheel_speed=-60, duration=1.75)\n",
    "                robot.wait_for_all_actions_completed()\n",
    "                robot.turn_in_place(degrees(correct), speed=Angle(30)).wait_for_completed()\n",
    "        else:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#       obj_lock.targeted and last_obj.same_object():\n",
    "#         if objQueue.empty():\n",
    "#         else:\n",
    "#             box = objQueue.get()\n",
    "#             go_to_object(robot, box)\n",
    "\n",
    "#   obj_diff, avg_certainty = last_obj.check_again(y_center, x_center, score)\n",
    "#   obj_lock.add(turn, drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class obj_wrapper:\n",
    "#     def __init__(self, ymin, ymax, xmin, xmax):    \n",
    "#         self.height = ymax - ymin\n",
    "#         self.width = xmax - xmin\n",
    "#         self.area = self.height * self.width\n",
    "#         self.centroid = (0,0)\n",
    "        \n",
    "#         self.position = (-1,-1,-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# class obj_certainty:\n",
    "#     '''\n",
    "#     an aggregate of the last several images from the Image Queue\n",
    "#     '''\n",
    "#     def __init__(self):\n",
    "#         self.last_xcenter=0.0\n",
    "#         self.last_ycenter=0.0\n",
    "#         self.total_score=0.0\n",
    "#         self.check_ctr=0\n",
    "        \n",
    "#         self.avg_score = 0.1\n",
    "#         self.dist = 100\n",
    "        \n",
    "#     def check_again(self, y_center, x_center, score):\n",
    "#         '''\n",
    "#         check (Euclidean) distance between the \n",
    "#         center of this box in the frame and the previously seen box\n",
    "#         '''\n",
    "#         self.check_ctr+=1\n",
    "#         if self.check_ctr is not 1:\n",
    "#             self.dist = math.sqrt((x_center - self.last_xcenter)**2 + \n",
    "#                          (y_center - self.last_ycenter)**2)\n",
    "#         else:\n",
    "#             self.dist = 0\n",
    "            \n",
    "#         self.total_score += score\n",
    "#         avg_score = self.total_score/self.check_ctr  \n",
    "#         return self.dist, self.avg_score\n",
    "    \n",
    "#     def average_score(self, score):\n",
    "#         return self.avg_score\n",
    "    \n",
    "#     def num_checks(self):\n",
    "#         return self.check_ctr\n",
    "    \n",
    "#     def same_object(self):\n",
    "#         if self.avg_score > 0.099 and self.dist < 400:\n",
    "#             same = True # make these more specific\n",
    "#         else:\n",
    "#             same = False\n",
    "#         return same\n",
    "        \n",
    "#             # different object.      \n",
    "#     # Which object am I seeing the most? / Which bounding box is the most consistent?\n",
    "#     # Which avg. bounding box has the most consistently high probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class robot_obj_lock:\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         self.moves=0\n",
    "#         self.turn_angle=0\n",
    "#         self.drive_dist=0\n",
    "#         self.targeted=True\n",
    "#         self.lost_target=False\n",
    "        \n",
    "#     def has_moved(self):\n",
    "#         if self.turn_angle or self.drive_dist:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "        \n",
    "#     def num_moves(self):\n",
    "#         return self.moves\n",
    "    \n",
    "#     def add(self, turn, drive):\n",
    "#         self.drive_dist+=drive\n",
    "#         self.turn_angle+=turn\n",
    "#         self.moves+=1\n",
    "# #         if self.moves > 5:\n",
    "# #             self.targeted = False\n",
    "# #             self.lost_target=True\n",
    "            \n",
    "#         if self.turn_angle > 50 or self.turn_angle < -50:\n",
    "#             self.targeted = False\n",
    "#             self.lost_target=True\n",
    "        \n",
    "#         if self.drive_dist > 200 or self.drive_dist < -100:\n",
    "#             self.targeted = False\n",
    "#             self.lost_target=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_obj(robot):\n",
    "#      while(True):\n",
    "#         if(not objQueue.empty()) and not robot.is_moving:\n",
    "#     robot.set_lift_height(1.0).wait_for_completed()\n",
    "#     robot.set_head_angle(cozmo.robot.MIN_HEAD_ANGLE).wait_for_completed()\n",
    "    \n",
    "#     found_obj = None\n",
    "\n",
    "#     while not found_obj:\n",
    "#         robot.turn_in_place(degrees(20), in_parallel=True) \n",
    "#         turn_action = None\n",
    "                \n",
    "#         if robot.world.visible_face_count() > 0:\n",
    "#             print(\"Found object!\")\n",
    "#             face_to_follow = next(robot.world.visible_faces, None)\n",
    "#             robot.wait_for_all_actions_completed()\n",
    "#         if turn_action:\n",
    "#             # Complete the turn action if one was in progress\n",
    "#             turn_action.wait_for_completed()\n",
    "\n",
    "#         time.sleep(.1)\n",
    "    \n",
    "#     print(\"Found object!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
